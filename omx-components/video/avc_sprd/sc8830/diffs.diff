diff --git a/omx-components/video/avc_sprd/sc8830/enc/Android.mk b/omx-components/video/avc_sprd/sc8830/enc/Android.mk
index 676e0ec..9125c13 100644
--- a/omx-components/video/avc_sprd/sc8830/enc/Android.mk
+++ b/omx-components/video/avc_sprd/sc8830/enc/Android.mk
@@ -1,26 +1,42 @@
 LOCAL_PATH := $(call my-dir)
+
 include $(CLEAR_VARS)
 
 LOCAL_SRC_FILES := \
-        SPRDAVCEncoder.cpp
+	SPRDAVCEncoder.cpp \
+	rgb2yuv_neon.s
 
 LOCAL_C_INCLUDES := \
-        frameworks/av/media/libstagefright/include \
+	frameworks/av/media/libstagefright/include \
+	frameworks/native/include/media/openmax \
 	frameworks/native/include/media/hardware \
 	frameworks/native/include \
 	$(TOP)/hardware/sprd/libstagefrighthw/include \
-	$(TOP)/hardware/sprd/libstagefrighthw/include/openmax \
 	$(TOP)/hardware/sprd/libmemion \
+	$(TOP)/hardware/sprd/libgpu/include \
 	$(TARGET_OUT_INTERMEDIATES)/KERNEL_OBJ/usr/include/video
 
-LOCAL_C_INCLUDES += $(TOP)/hardware/sprd/libgpu/include \
+LOCAL_ADDITIONAL_DEPENDENCIES += \
+	$(TARGET_OUT_INTERMEDIATES)/KERNEL_OBJ/usr
+
+LOCAL_CFLAGS := \
+	-DOSCL_EXPORT_REF= \
+	-DOSCL_IMPORT_REF=
 
-LOCAL_CFLAGS := -DOSCL_EXPORT_REF= -DOSCL_IMPORT_REF=
+LOCAL_LDFLAGS += -Wl,--no-warn-shared-textrel
 
 LOCAL_ARM_MODE := arm
 
 LOCAL_SHARED_LIBRARIES := \
-        libstagefright libstagefright_omx libstagefright_foundation libstagefrighthw libutils libui libmemion libdl liblog
+	libstagefright \
+	libstagefright_omx \
+	libstagefright_foundation \
+	libstagefrighthw \
+	libmemoryheapion \
+	libutils \
+	libui \
+	libdl \
+	liblog
 
 LOCAL_MODULE := libstagefright_sprd_h264enc
 LOCAL_MODULE_TAGS := optional
diff --git a/omx-components/video/avc_sprd/sc8830/enc/SPRDAVCEncoder.cpp b/omx-components/video/avc_sprd/sc8830/enc/SPRDAVCEncoder.cpp
index 713e6a4..55820c9 100644
--- a/omx-components/video/avc_sprd/sc8830/enc/SPRDAVCEncoder.cpp
+++ b/omx-components/video/avc_sprd/sc8830/enc/SPRDAVCEncoder.cpp
@@ -32,15 +32,22 @@
 
 #include <ui/Rect.h>
 #include <ui/GraphicBufferMapper.h>
-#include <dlfcn.h>
+//#include <gui/ISurfaceTexture.h>
 
 #include <linux/ion.h>
+#include <MemoryHeapIon.h>
 
-#include "MemoryHeapIon.h"
+#include <dlfcn.h>
 
 #include "SPRDAVCEncoder.h"
 #include "ion_sprd.h"
 #include "gralloc_priv.h"
+#include "OMX_Index.h"
+#ifdef CONVERT_THREAD
+#include <media/stagefright/foundation/ALooper.h>
+#include <media/stagefright/foundation/AMessage.h>
+
+#endif
 
 #define VIDEOENC_CURRENT_OPT
 
@@ -178,7 +185,7 @@ static status_t ConvertAvcSpecLevelToOmxAvcLevel(
  * FIXME: If width_org is not 16 aligned also, this would be much complicate
  *
  */
-inline static void ConvertYUV420PlanarToYVU420SemiPlanar(uint8_t *inyuv, uint8_t* outyuv,
+inline static void ConvertYUV420PlanarToYUV420SemiPlanar(uint8_t *inyuv, uint8_t* outyuv,
         int32_t width_org, int32_t height_org, int32_t width_dst, int32_t height_dst) {
 
     int32_t inYsize = width_org * height_org;
@@ -227,21 +234,21 @@ inline static void inittable()
     ALOGI("init table");
     int i = 0;
     for(i = 0; i < 256; i++) {
-        RGB_r_y[i] =  (66 * i);
-        RGB_r_cb[i] = (38 * i);
-        RGB_r_cr_b_cb[i] = (112 * i);
-        RGB_g_y[i] = (129 * i);
-        RGB_g_cb[i] = (74 * i) ;
-        RGB_g_cr[i] = (94 * i);
-        RGB_b_y[i] =  (25 * i);
-        RGB_b_cr[i] = (18 * i);
+        RGB_r_y[i] =  ((66 * i) >> 8);
+        RGB_r_cb[i] = ((38 * i) >> 8);
+        RGB_r_cr_b_cb[i] = ((112 * i) >> 8 );
+        RGB_g_y[i] = ((129 * i) >> 8) + 16 ;
+        RGB_g_cb[i] = ((74 * i) >> 8) + 128 ;
+        RGB_g_cr[i] = ((94 * i) >> 8) + 128;
+        RGB_b_y[i] =  ((25 * i) >> 8);
+        RGB_b_cr[i] = ((18 * i) >> 8);
     }
 }
-inline static void ConvertARGB888ToYVU420SemiPlanar(uint8_t *inrgb, uint8_t* outy,uint8_t* outuv,
+inline static void ConvertARGB888ToYUV420SemiPlanar(uint8_t *inrgb, uint8_t* outy,uint8_t* outuv,
         int32_t width_org, int32_t height_org, int32_t width_dst, int32_t height_dst) {
-#define RGB2Y(_r, _g, _b)    ((  *(RGB_r_y +_r)      +   *(RGB_g_y+_g)   +    *(RGB_b_y+_b)) >> 8) + 16;
-#define RGB2CB(_r, _g, _b)   (( -*(RGB_r_cb +_r)     -   *(RGB_g_cb+_g)  +    *(RGB_r_cr_b_cb+_b)) >> 8) + 128;
-#define RGB2CR(_r, _g, _b)   ((  *(RGB_r_cr_b_cb +_r)-   *(RGB_g_cr+_g)  -    *(RGB_b_cr+_b))>>8) + 128;
+#define RGB2Y(_r, _g, _b)    (  *(RGB_r_y +_r)      +   *(RGB_g_y+_g)   +    *(RGB_b_y+_b))
+#define RGB2CB(_r, _g, _b)   ( -*(RGB_r_cb +_r)     -   *(RGB_g_cb+_g)  +    *(RGB_r_cr_b_cb+_b))
+#define RGB2CR(_r, _g, _b)   (  *(RGB_r_cr_b_cb +_r)-   *(RGB_g_cr+_g)  -    *(RGB_b_cr+_b))
     uint8_t *argb_ptr = inrgb;
     uint8_t *y_p = outy;
     //uint8_t *vu_p = outyuv + width_dst * height_dst;
@@ -249,15 +256,8 @@ inline static void ConvertARGB888ToYVU420SemiPlanar(uint8_t *inrgb, uint8_t* out
 
     if (NULL == inrgb || NULL ==  outy || NULL == outuv)
         return;
-
-    if (height_org & 0x1 != 0)
-        height_org &= ~0x1;
-
-    if (width_org & 0x1 != 0) {
-        ALOGE("width_org:%d is not supported", width_org);
+    if (0 != (width_org & 1) || 0 != (height_org & 1))
         return;
-    }
-
     if(!mConventFlag) {
         mConventFlag = true;
         inittable();
@@ -278,7 +278,7 @@ inline static void ConvertARGB888ToYVU420SemiPlanar(uint8_t *inrgb, uint8_t* out
             vu_p += width_dst;
             i  = width_org / 2 + 1;
             while(--i) {
-                //format abgr, little endian
+                //format abgr, litter endian
                 *y_ptr++    = RGB2Y(*argb_ptr, *(argb_ptr+1), *(argb_ptr+2));
                 *vu_ptr++ =  RGB2CR(*argb_ptr, *(argb_ptr+1), *(argb_ptr+2));
                 *vu_ptr++  = RGB2CB(*argb_ptr, *(argb_ptr+1), *(argb_ptr+2));
@@ -297,100 +297,11 @@ inline static void ConvertARGB888ToYVU420SemiPlanar(uint8_t *inrgb, uint8_t* out
     int64_t end_encode = systemTime();
     ALOGI("rgb2yuv time: %d",(unsigned int)((end_encode-start_encode) / 1000000L));
 }
-
-/*this is neon assemble function.It is need width_org align in 16Bytes.height_org align in 2Bytes*/
-/*in cpu not busy status,it deal with 1280*720 rgb data in 5-6ms */
-extern "C" void neon_intrinsics_ARGB888ToYVU420Semi(uint8_t *inrgb, uint8_t* outy,uint8_t* outuv,
+extern "C" void neon_intrinsics_ARGB888ToYUV420Semi(uint8_t *inrgb, uint8_t* outy,uint8_t* outuv,
                     int32_t width_org, int32_t height_org, int32_t width_dst, int32_t height_dst);
 
-/*this is neon c function.It is need width_org align in 2Bytes.height_org align in 2Bytes*/
-/*like ConvertARGB888ToYVU420SemiPlanar function parameters requirement*/
-/*in cpu not busy status,it deal with 1280*720 rgb data in 5-6ms */
-void neon_intrinsics_ARGB888ToYVU420Semi_c(uint8_t *inrgb, uint8_t* outy,uint8_t* outuv,
-                    int32_t width_org, int32_t height_org, int32_t width_dst, int32_t height_dst){
-   int32_t i, j;
-   uint8_t *argb_ptr = inrgb;
-   uint8_t *y_ptr = outy;
-   uint8_t *temp_y_ptr = y_ptr;
-   uint8_t *uv_ptr = outuv;
-   uint8_t *argb_tmpptr ;
-   uint8x8_t r1fac = vdup_n_u8(66);
-   uint8x8_t g1fac = vdup_n_u8(129);
-   uint8x8_t b1fac = vdup_n_u8(25);
-   uint8x8_t r2fac = vdup_n_u8(38);
-   uint8x8_t g2fac = vdup_n_u8(74);
-   uint8x8_t b2fac = vdup_n_u8(112);
-   // int8x8_t r3fac = vdup_n_s16(112);
-   uint8x8_t g3fac = vdup_n_u8(94);
-   uint8x8_t b3fac = vdup_n_u8(18);
-
-   uint8x8_t y_base = vdup_n_u8(16);
-   uint8x8_t uv_base = vdup_n_u8(128);
-
-   bool needadjustPos = true;
-   //due to width_dst is align in 16Bytes.so if width_org is align in 16bytes.no need adjust pos.
-   if(width_org%16 == 0){
-       needadjustPos = false;
-   }
-   int32_t linecount=0;
-   for (i=height_org; i>0; i--)    /////  line
-   {
-      for (j=(width_org>>3); j>0; j--)   ///// col
-      {
-          uint8 y, cb, cr;
-          int8 r, g, b;
-          uint8 p_r[16],p_g[16],p_b[16];
-          uint16x8_t temp;
-          uint8x8_t result;
-          uint8x8x2_t result_uv;
-          uint8x8_t result_u;
-          uint8x8_t result_v;
-
-          // y = RGB2Y(r, g, b);
-          uint8x8x4_t argb = vld4_u8(argb_ptr);
-          temp = vmull_u8(argb.val[0],r1fac);    ///////////////////////y  0,1,2
-          temp = vmlal_u8(temp,argb.val[1],g1fac);
-          temp = vmlal_u8(temp,argb.val[2],b1fac);
-          result = vshrn_n_u16(temp,8);
-          result = vadd_u8(result,y_base);
-          vst1_u8(y_ptr,result);     ////*y_ptr = y;
-
-          if(linecount%2==0){
-              //cb = RGB2CR(r, g, b);
-              temp = vmull_u8(argb.val[2],b2fac);    ///////////////////////cb
-              temp = vmlsl_u8(temp,argb.val[1],g2fac);
-              temp = vmlsl_u8(temp,argb.val[0],r2fac);
-              result_u = vshrn_n_u16(temp,8);
-              result_u = vadd_u8(result_u,uv_base);
-
-              //cr = RGB2CB(r, g, b);
-              temp = vmull_u8(argb.val[0],b2fac);    ///////////////////////cr
-              temp = vmlsl_u8(temp,argb.val[1],g3fac);
-              temp = vmlsl_u8(temp,argb.val[2],b3fac);
-              result_v = vshrn_n_u16(temp,8);
-              result_v = vadd_u8(result_v,uv_base);
-
-              result_uv = vtrn_u8( result_v,result_u );/////uuuuuuuuvvvvvvvv -->> uvuvuvuvuvuvuvuvuv
-              vst1_u8(uv_ptr,result_uv.val[0]);
-              uv_ptr += 8;
-          }
-          y_ptr += 8;
-          argb_ptr += 32;
-      }
-      linecount++;
-      if(needadjustPos){
-          //note:let y,uv,argb get correct position before operating next line.
-          y_ptr = outy + width_dst*linecount;
-          uv_ptr = outuv + width_dst*(linecount/2);
-          argb_ptr = inrgb + 4*width_org*linecount;
-      }
-   }
-}
-
-
-
 #if 0
-void neon_intrinsics_ARGB888ToYVU420Semi(uint8_t *inrgb, uint8_t* outy,uint8_t* outuv,
+void neon_intrinsics_ARGB888ToYUV420Semi(uint8_t *inrgb, uint8_t* outy,uint8_t* outuv,
                     int32_t width_org, int32_t height_org, int32_t width_dst, int32_t height_dst){
    uint32_t i, j;
    uint8_t *argb_ptr = inrgb;
@@ -510,9 +421,8 @@ void neon_intrinsics_ARGB888ToYVU420Semi(uint8_t *inrgb, uint8_t* outy,uint8_t*
       argb_ptr += width_org<<2;
    }
 }
-#endif //, neon_intrinsics_ARGB888ToYVU420Semi
-
-inline static void ConvertARGB888ToYVU420SemiPlanar_neon(uint8_t *inrgb, uint8_t* outy,uint8_t* outuv,
+#endif
+inline static void ConvertARGB888ToYUV420SemiPlanar_neon(uint8_t *inrgb, uint8_t* outy,uint8_t* outuv,
                     int32_t width_org, int32_t height_org, int32_t width_dst, int32_t height_dst) {
 #define RGB2Y(_r, _g, _b) (((66 * (_r) + 129 * (_g) + 25 * (_b)) >> 8) + 16)
 #define RGB2CB(_r, _g, _b) (((-38 * (_r) - 74 * (_g) + 112 * (_b)) >> 8) + 128)
@@ -526,19 +436,14 @@ inline static void ConvertARGB888ToYVU420SemiPlanar_neon(uint8_t *inrgb, uint8_t
     if (NULL == inrgb || NULL == outuv || NULL==outy)
         return;
 
-    if (height_org & 0x1 != 0)
-        height_org &= ~0x1;
-
-    if (width_org & 0x1 != 0) {
-        ALOGE("width_org:%d is not supported", width_org);
+    if (0 != (width_org & 1) || 0 != (height_org & 1))
         return;
-    }
 
     int64_t start_encode = systemTime();
-    neon_intrinsics_ARGB888ToYVU420Semi_c(inrgb,  y_ptr, vu_ptr,                         //  1280*720  =>  22ms in padv2
+    neon_intrinsics_ARGB888ToYUV420Semi(inrgb,  y_ptr, vu_ptr,                         //  1280*720  =>  22ms in padv2
                                         width_org,  height_org,  width_dst,  height_dst);
     int64_t end_encode = systemTime();
-    ALOGI("wfd: ConvertARGB888ToYVU420SemiPlanar_neon:  rgb2yuv cost time: %d",(unsigned int)((end_encode-start_encode) / 1000000L));
+    ALOGI("wfd: ConvertARGB888ToYUV420SemiPlanar_neon:  rgb2yuv cost time: %d",(unsigned int)((end_encode-start_encode) / 1000000L));
 }
 
 #ifdef VIDEOENC_CURRENT_OPT
@@ -563,46 +468,41 @@ SPRDAVCEncoder::SPRDAVCEncoder(
     OMX_PTR appData,
     OMX_COMPONENTTYPE **component)
     : SprdSimpleOMXComponent(name, callbacks, appData, component),
-      mHandle(new tagAVCHandle),
-      mEncParams(new tagAVCEncParam),
-      mEncConfig(new MMEncConfig),
-      mSliceGroup(NULL),
-      mNumInputFrames(-1),
-      mPrevTimestampUs(-1),
-      mSetFreqCount(0),
       mVideoWidth(176),
       mVideoHeight(144),
       mVideoFrameRate(30),
       mVideoBitRate(192000),
-      mBitrate(0),
-      mEncSceneMode(0),
-      mSetEncMode(false),
-      mVideoColorFormat(OMX_SPRD_COLOR_FormatYVU420SemiPlanar),
-      mStoreMetaData(OMX_FALSE),
-      mPrependSPSPPS(OMX_FALSE),
-      mIOMMUEnabled(false),
-      mIOMMUID(-1),
+      mVideoColorFormat(OMX_COLOR_FormatYUV420SemiPlanar),
+      mAVCEncProfile(AVC_BASELINE),
+      mAVCEncLevel(AVC_LEVEL2),
+      mPFrames(29),
+      mNumInputFrames(-1),
+      mPrevTimestampUs(-1),
       mStarted(false),
       mSpsPpsHeaderReceived(false),
       mReadyForNextFrame(true),
       mSawInputEOS(false),
       mSignalledError(false),
-      mKeyFrameRequested(false),
-      mIschangebitrate(false),
-      mPbuf_inter(NULL),
+      mStoreMetaData(OMX_FALSE),
+      mPrependSPSPPS(OMX_FALSE),
+      mIOMMUEnabled(false),
       mPbuf_yuv_v(NULL),
       mPbuf_yuv_p(0),
       mPbuf_yuv_size(0),
-      mPbuf_stream_v(NULL),
-      mPbuf_stream_p(0),
-      mPbuf_stream_size(0),
+      mPbuf_inter(NULL),
       mPbuf_extra_v(NULL),
       mPbuf_extra_p(0),
       mPbuf_extra_size(0),
-      mAVCEncProfile(AVC_BASELINE),
-      mAVCEncLevel(AVC_LEVEL2),
-      mPFrames(29),
+      mPbuf_stream_v(NULL),
+      mPbuf_stream_p(0),
+      mPbuf_stream_size(0),
+      mHandle(new tagAVCHandle),
+      mEncConfig(new MMEncConfig),
+      mEncParams(new tagAVCEncParam),
+      mSliceGroup(NULL),
+      mSetFreqCount(0),
       mLibHandle(NULL),
+      mH264EncGetCodecCapability(NULL),
       mH264EncPreInit(NULL),
       mH264EncInit(NULL),
       mH264EncSetConf(NULL),
@@ -610,9 +510,9 @@ SPRDAVCEncoder::SPRDAVCEncoder(
       mH264EncStrmEncode(NULL),
       mH264EncGenHeader(NULL),
       mH264EncRelease(NULL),
-      mH264EncGetCodecCapability(NULL) {
+      mKeyFrameRequested(false) {
 
-    ALOGI("Construct SPRDAVCEncoder, this: 0x%p", (void *)this);
+    ALOGI("Construct SPRDAVCEncoder, this: %0x", (void *)this);
 
     CHECK(mHandle != NULL);
     memset(mHandle, 0, sizeof(tagAVCHandle));
@@ -624,23 +524,17 @@ SPRDAVCEncoder::SPRDAVCEncoder(
 
     CHECK_EQ(openEncoder("libomx_avcenc_hw_sprd.so"), true);
 
-    ALOGI("%s, line:%d, name: %s", __FUNCTION__, __LINE__, name);
+    ALOGI("%s, %d, name: %s", __FUNCTION__, __LINE__, name);
 
-    if (MemoryHeapIon::IOMMU_is_enabled(ION_MM)) {
-        mIOMMUEnabled = true;
-        mIOMMUID = ION_MM;
-    } else if (MemoryHeapIon::IOMMU_is_enabled(ION_VSP)) {
-        mIOMMUEnabled = true;
-        mIOMMUID = ION_VSP;
-    }
-    ALOGI("%s, is IOMMU enabled: %d, ID: %d", __FUNCTION__, mIOMMUEnabled, mIOMMUID);
+    mIOMMUEnabled = MemoryHeapIon::Mm_iommu_is_enabled();
+    ALOGI("%s, is IOMMU enabled: %d", __FUNCTION__, mIOMMUEnabled);
 
     MMCodecBuffer InterMemBfr;
-    uint32_t size_inter = H264ENC_INTERNAL_BUFFER_SIZE;
+    int32 size_inter = H264ENC_INTERNAL_BUFFER_SIZE;
 
-    mPbuf_inter = (uint8_t *)malloc(size_inter);
+    mPbuf_inter = (uint8 *)malloc(size_inter);
     CHECK(mPbuf_inter != NULL);
-    InterMemBfr.common_buffer_ptr = mPbuf_inter;
+    InterMemBfr.common_buffer_ptr = (uint8 *)mPbuf_inter;
     InterMemBfr.common_buffer_ptr_phy= 0;
     InterMemBfr.size = size_inter;
 
@@ -653,16 +547,48 @@ SPRDAVCEncoder::SPRDAVCEncoder(
           mCapability.profile, mCapability.level, mCapability.max_width, mCapability.max_height);
 
 #ifdef SPRD_DUMP_YUV
-    mFile_yuv = fopen("/data/dump/video_in.yuv", "ab");
+    mFile_yuv = fopen("/data/video.yuv", "wb");
 #endif
 
 #ifdef SPRD_DUMP_BS
     mFile_bs = fopen("/data/video.h264", "wb");
 #endif
+
+
+
+#ifdef CONVERT_THREAD
+
+
+    mIncomingBufNum = 0;
+    mCurrentNeedBufNum = 0;
+    mBufIndex = 0;
+    mLooper_enc = new ALooper;
+    mHandler_enc = new AHandlerReflector<SPRDAVCEncoder>(this);
+    mLooper_enc->setName("convert_looper");
+    mLooper_enc->registerHandler(mHandler_enc);
+    mLooper_enc->start(
+        false, // runOnCallingThread
+        false, // canCallJava
+        ANDROID_PRIORITY_AUDIO);
+
+    for (int i=0;i<CONVERT_MAX_THREAD_NUM;i++)
+    {
+        mLooper_rgb2yuv[i] = new ALooper;
+        mHandler_rgb2yuv[i] = new MyRGB2YUVThreadHandle(this,i);
+        mLooper_rgb2yuv[i]->setName("rgb2yuv_looper"+i);
+        mLooper_rgb2yuv[i]->registerHandler(mHandler_rgb2yuv[i]);
+        mLooper_rgb2yuv[i]->start(
+        false, // runOnCallingThread
+        false, // canCallJava
+        ANDROID_PRIORITY_AUDIO);
+        rgb2yuv_thread_status[i] = RGB2YUR_THREAD_READY;
+        //ALOGI("wfd: start rgb2yuv_looper%d",i);
+    }
+#endif
 }
 
 SPRDAVCEncoder::~SPRDAVCEncoder() {
-    ALOGI("Destruct SPRDAVCEncoder, this: 0x%p", (void *)this);
+    ALOGI("Destruct SPRDAVCEncoder, this: %0x", (void *)this);
 
     releaseEncoder();
 
@@ -692,6 +618,17 @@ SPRDAVCEncoder::~SPRDAVCEncoder() {
         mFile_bs = NULL;
     }
 #endif
+
+#ifdef CONVERT_THREAD
+    mLooper_enc->unregisterHandler(mHandler_enc->id());
+    mLooper_enc->stop();
+    for (int i=0;i<CONVERT_MAX_THREAD_NUM;i++)
+    {
+        mLooper_rgb2yuv[i]->unregisterHandler(mHandler_rgb2yuv[i]->id());
+        mLooper_rgb2yuv[i]->stop();
+        rgb2yuv_thread_status[i] = RGB2YUR_THREAD_STOPED;
+    }
+#endif
 }
 
 OMX_ERRORTYPE SPRDAVCEncoder::initEncParams() {
@@ -750,11 +687,10 @@ OMX_ERRORTYPE SPRDAVCEncoder::initEncParams() {
 
     MMCodecBuffer ExtraMemBfr;
     MMCodecBuffer StreamMemBfr;
-    unsigned long phy_addr = 0;
-    size_t size = 0;
-    size_t size_of_yuv = ((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15)) * 3/2;
+    int32 phy_addr = 0;
+    int32 size = 0;
 
-    size_t size_extra = size_of_yuv << 1;
+    unsigned int size_extra = ((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15)) * 3/2 * 2;
     size_extra += (406*2*sizeof(uint32));
     size_extra += 1024;
     if (mIOMMUEnabled) {
@@ -763,73 +699,76 @@ OMX_ERRORTYPE SPRDAVCEncoder::initEncParams() {
         mPmem_extra = new MemoryHeapIon("/dev/ion", size_extra, MemoryHeapIon::NO_CACHING, ION_HEAP_ID_MASK_MM);
     }
     if (mPmem_extra->getHeapID() < 0) {
-        ALOGE("Failed to alloc extra buffer (%zd), getHeapID failed", size_extra);
-        return OMX_ErrorInsufficientResources;
-    }
-
-    int ret;
-    if (mIOMMUEnabled) {
-       ret = mPmem_extra->get_iova(mIOMMUID, &phy_addr, &size);
-    } else {
-        ret = mPmem_extra->get_phy_addr_from_ion(&phy_addr, &size);
-    }
-    if (ret < 0) {
-        ALOGE("Failed to alloc extra buffer, get phy addr failed");
+        ALOGE("Failed to alloc extra buffer (%d), getHeapID failed", size_extra);
         return OMX_ErrorInsufficientResources;
+    } else
+    {
+        int32 ret;
+        if (mIOMMUEnabled) {
+            ret = mPmem_extra->get_mm_iova(&phy_addr, &size);
+        } else {
+            ret = mPmem_extra->get_phy_addr_from_ion(&phy_addr, &size);
+        }
+        if (ret < 0)
+        {
+            ALOGE("Failed to alloc extra buffer, get phy addr failed");
+            return OMX_ErrorInsufficientResources;
+        } else
+        {
+            mPbuf_extra_v = (unsigned char*)mPmem_extra->base();
+            mPbuf_extra_p = (int32)phy_addr;
+            mPbuf_extra_size = (int32)size;
+        }
     }
 
-    mPbuf_extra_v = (uint8_t*)mPmem_extra->getBase();
-    mPbuf_extra_p = phy_addr;
-    mPbuf_extra_size = size;
-
-    size_t size_stream = size_of_yuv >> 1;
+    unsigned int size_stream = ONEFRAME_BITSTREAM_BFR_SIZE;
     if (mIOMMUEnabled) {
-        mPmem_stream = new MemoryHeapIon("/dev/ion", size_stream, MemoryHeapIon::NO_CACHING, ION_HEAP_ID_MASK_SYSTEM);
+        mPmem_stream = new MemoryHeapIon("/dev/ion", size_stream, MemoryHeapBase::NO_CACHING, ION_HEAP_ID_MASK_SYSTEM);
     } else {
-        mPmem_stream = new MemoryHeapIon("/dev/ion", size_stream, MemoryHeapIon::NO_CACHING, ION_HEAP_ID_MASK_MM);
+        mPmem_stream = new MemoryHeapIon("/dev/ion", size_stream, MemoryHeapBase::NO_CACHING, ION_HEAP_ID_MASK_MM);
     }
     if (mPmem_stream->getHeapID() < 0) {
-        ALOGE("Failed to alloc stream buffer (%zd), getHeapID failed", size_stream);
-        return OMX_ErrorInsufficientResources;
-    }
-
-    if (mIOMMUEnabled) {
-        ret = mPmem_stream->get_iova(mIOMMUID, &phy_addr, &size);
-    } else {
-        ret = mPmem_stream->get_phy_addr_from_ion(&phy_addr, &size);
-    }
-    if (ret < 0) {
-        ALOGE("Failed to alloc stream buffer, get phy addr failed");
+        ALOGE("Failed to alloc stream buffer (%d), getHeapID failed", size_stream);
         return OMX_ErrorInsufficientResources;
+    } else
+    {
+        int32 ret;
+        if (mIOMMUEnabled) {
+            ret = mPmem_stream->get_mm_iova(&phy_addr, &size);
+        } else {
+            ret = mPmem_stream->get_phy_addr_from_ion(&phy_addr, &size);
+        }
+        if (ret < 0)
+        {
+            ALOGE("Failed to alloc stream buffer, get phy addr failed");
+            return OMX_ErrorInsufficientResources;
+        } else
+        {
+            mPbuf_stream_v = (unsigned char*)mPmem_stream->base();
+            mPbuf_stream_p = (int32)phy_addr;
+            mPbuf_stream_size = (int32)size;
+        }
     }
 
-    mPbuf_stream_v = (uint8_t*)mPmem_stream->getBase();
-    mPbuf_stream_p = phy_addr;
-    mPbuf_stream_size = size;
-
     ExtraMemBfr.common_buffer_ptr = mPbuf_extra_v;
-    ExtraMemBfr.common_buffer_ptr_phy = mPbuf_extra_p;
-    ExtraMemBfr.size = size_extra;
+    ExtraMemBfr.common_buffer_ptr_phy = (void*)mPbuf_extra_p;
+    ExtraMemBfr.size	= size_extra;
 
     StreamMemBfr.common_buffer_ptr = mPbuf_stream_v;
-    StreamMemBfr.common_buffer_ptr_phy = mPbuf_stream_p;
-    StreamMemBfr.size = size_stream;
+    StreamMemBfr.common_buffer_ptr_phy = (void *)mPbuf_stream_p;
+    StreamMemBfr.size	= size_stream;
 
     mEncInfo.is_h263 = 0;
     mEncInfo.frame_width = mVideoWidth;
     mEncInfo.frame_height = mVideoHeight;
-    if (mVideoColorFormat == OMX_COLOR_FormatYUV420SemiPlanar) {
-        mEncInfo.yuv_format = MMENC_YUV420SP_NV12;
-    } else {
-        mEncInfo.yuv_format = MMENC_YUV420SP_NV21;
-    }
-
+    mEncInfo.yuv_format = MMENC_YUV420SP_NV21;
     mEncInfo.time_scale = 1000;
 #ifdef ANTI_SHAKE
     mEncInfo.b_anti_shake = 1;
 #else
     mEncInfo.b_anti_shake = 0;
 #endif
+    mEncInfo.cabac_en = 0;
 
     if ((*mH264EncInit)(mHandle, &ExtraMemBfr,&StreamMemBfr, &mEncInfo)) {
         ALOGE("Failed to init mp4enc");
@@ -846,12 +785,12 @@ OMX_ERRORTYPE SPRDAVCEncoder::initEncParams() {
     mEncConfig->targetBitRate = mVideoBitRate;
     mEncConfig->FrameRate = mVideoFrameRate;
     mEncConfig->PFrames = mPFrames;
-    mEncConfig->QP_IVOP = 36;
+    mEncConfig->QP_IVOP = 28;
     mEncConfig->QP_PVOP = 28;
     mEncConfig->vbv_buf_size = mVideoBitRate/2;
     mEncConfig->profileAndLevel = 1;
     mEncConfig->PrependSPSPPSEnalbe = ((mPrependSPSPPS == OMX_FALSE) ? 0 : 1);
-    mEncConfig->EncSceneMode = mEncSceneMode;
+
     if ((*mH264EncSetConf)(mHandle, mEncConfig)) {
         ALOGE("Failed to set default encoding parameters");
         return OMX_ErrorUndefined;
@@ -904,9 +843,10 @@ OMX_ERRORTYPE SPRDAVCEncoder::releaseEncoder() {
 
 OMX_ERRORTYPE SPRDAVCEncoder::releaseResource() {
 
-    if (mPbuf_extra_v != NULL) {
+    if (mPbuf_extra_v != NULL)
+    {
         if (mIOMMUEnabled) {
-            mPmem_extra->free_iova(mIOMMUID, mPbuf_extra_p, mPbuf_extra_size);
+            mPmem_extra->free_mm_iova(mPbuf_extra_p, mPbuf_extra_size);
         }
         mPmem_extra.clear();
         mPbuf_extra_v = NULL;
@@ -914,9 +854,10 @@ OMX_ERRORTYPE SPRDAVCEncoder::releaseResource() {
         mPbuf_extra_size = 0;
     }
 
-    if (mPbuf_stream_v != NULL) {
+    if (mPbuf_stream_v != NULL)
+    {
         if (mIOMMUEnabled) {
-            mPmem_stream->free_iova(mIOMMUID, mPbuf_stream_p, mPbuf_stream_size);
+            mPmem_stream->free_mm_iova(mPbuf_stream_p, mPbuf_stream_size);
         }
         mPmem_stream.clear();
         mPbuf_stream_v = NULL;
@@ -926,7 +867,7 @@ OMX_ERRORTYPE SPRDAVCEncoder::releaseResource() {
 
     if (mPbuf_yuv_v != NULL) {
         if (mIOMMUEnabled) {
-            mYUVInPmemHeap->free_iova(mIOMMUID, mPbuf_yuv_p, mPbuf_yuv_size);
+            mYUVInPmemHeap->free_mm_iova(mPbuf_yuv_p, mPbuf_yuv_size);
         }
         mYUVInPmemHeap.clear();
         mPbuf_yuv_v = NULL;
@@ -967,7 +908,7 @@ void SPRDAVCEncoder::initPorts() {
 
     def.nPortIndex = 0;
     def.eDir = OMX_DirInput;
-    def.nBufferCountMin = kNumBuffers;
+    def.nBufferCountMin = 4;//kNumBuffers;
     def.nBufferCountActual = def.nBufferCountMin;
     def.nBufferSize = kInputBufferSize;
     def.bEnabled = OMX_TRUE;
@@ -978,7 +919,7 @@ void SPRDAVCEncoder::initPorts() {
 
     def.format.video.cMIMEType = const_cast<char *>("video/raw");
     def.format.video.eCompressionFormat = OMX_VIDEO_CodingUnused;
-    def.format.video.eColorFormat = OMX_SPRD_COLOR_FormatYVU420SemiPlanar;
+    def.format.video.eColorFormat = OMX_COLOR_FormatYUV420SemiPlanar;
     def.format.video.xFramerate = (mVideoFrameRate << 16);  // Q16 format
     def.format.video.nBitrate = mVideoBitRate;
     def.format.video.nFrameWidth = mVideoWidth;
@@ -990,7 +931,7 @@ void SPRDAVCEncoder::initPorts() {
 
     def.nPortIndex = 1;
     def.eDir = OMX_DirOutput;
-    def.nBufferCountMin = kNumBuffers;
+    def.nBufferCountMin = 4;//kNumBuffers;
     def.nBufferCountActual = def.nBufferCountMin;
     def.nBufferSize = kOutputBufferSize;
     def.bEnabled = OMX_TRUE;
@@ -1043,18 +984,16 @@ OMX_ERRORTYPE SPRDAVCEncoder::internalGetParameter(
             return OMX_ErrorUndefined;
         }
 
-        if (formatParams->nIndex > 3) {
+        if (formatParams->nIndex > 2) {
             return OMX_ErrorNoMore;
         }
 
         if (formatParams->nPortIndex == 0) {
             formatParams->eCompressionFormat = OMX_VIDEO_CodingUnused;
             if (formatParams->nIndex == 0) {
-                formatParams->eColorFormat = OMX_SPRD_COLOR_FormatYVU420SemiPlanar;
+                formatParams->eColorFormat = OMX_COLOR_FormatYUV420Planar;
             } else if (formatParams->nIndex == 1) {
                 formatParams->eColorFormat = OMX_COLOR_FormatYUV420SemiPlanar;
-            } else if (formatParams->nIndex == 2) {
-                formatParams->eColorFormat = OMX_COLOR_FormatYUV420Planar;
             } else {
                 formatParams->eColorFormat = OMX_COLOR_FormatAndroidOpaque;
             }
@@ -1140,7 +1079,7 @@ OMX_ERRORTYPE SPRDAVCEncoder::internalGetParameter(
             }
         }
 
-        if (index < size && profileLevel->eLevel > ConversionTable[index].omxLevel) {
+        if (profileLevel->eLevel > ConversionTable[index].omxLevel) {
             profileLevel->eLevel = ConversionTable[index].omxLevel;
         }
         //ALOGI("Query supported profile level = %d, %d",profileLevel->eProfile, profileLevel->eLevel);
@@ -1150,119 +1089,10 @@ OMX_ERRORTYPE SPRDAVCEncoder::internalGetParameter(
     case OMX_IndexParamStoreMetaDataBuffer:
     {
         StoreMetaDataInBuffersParams *pStoreMetaData = (StoreMetaDataInBuffersParams *)params;
-        if (pStoreMetaData->nPortIndex != 0) {
-            ALOGE("%s: StoreMetadataInBuffersParams.nPortIndex not zero!",
-                    __FUNCTION__);
-            return OMX_ErrorUndefined;
-        }
-
         pStoreMetaData->bStoreMetaData = mStoreMetaData;
         return OMX_ErrorNone;
     }
 
-    case OMX_IndexParamDescribeColorFormat:
-    {
-        DescribeColorFormatParams *pDescribeColorFormat = (DescribeColorFormatParams *)params;
-
-        MediaImage &image = pDescribeColorFormat->sMediaImage;
-        memset(&image, 0, sizeof(image));
-
-        image.mType = MediaImage::MEDIA_IMAGE_TYPE_UNKNOWN;
-        image.mNumPlanes = 0;
-
-        const OMX_COLOR_FORMATTYPE fmt = pDescribeColorFormat->eColorFormat;
-        image.mWidth = pDescribeColorFormat->nFrameWidth;
-        image.mHeight = pDescribeColorFormat->nFrameHeight;
-
-        ALOGI("%s, DescribeColorFormat: 0x%x, w h = %d %d", __FUNCTION__,
-                pDescribeColorFormat->eColorFormat,
-                pDescribeColorFormat->nFrameWidth, pDescribeColorFormat->nFrameHeight);
-
-        if (fmt != OMX_SPRD_COLOR_FormatYVU420SemiPlanar &&
-            fmt != OMX_COLOR_FormatYUV420SemiPlanar &&
-            fmt != OMX_COLOR_FormatYUV420Planar) {
-            ALOGW("do not know color format 0x%x = %d", fmt, fmt);
-            return OMX_ErrorUnsupportedSetting;
-        }
-
-        // TEMPORARY FIX for some vendors that advertise sliceHeight as 0
-        if (pDescribeColorFormat->nStride != 0 && pDescribeColorFormat->nSliceHeight == 0) {
-            ALOGW("using sliceHeight=%u instead of what codec advertised (=0)",
-                    pDescribeColorFormat->nFrameHeight);
-            pDescribeColorFormat->nSliceHeight = pDescribeColorFormat->nFrameHeight;
-        }
-
-        // we need stride and slice-height to be non-zero
-        if (pDescribeColorFormat->nStride == 0 || pDescribeColorFormat->nSliceHeight == 0) {
-            ALOGW("cannot describe color format 0x%x = %d with stride=%u and sliceHeight=%u",
-                    fmt, fmt, pDescribeColorFormat->nStride, pDescribeColorFormat->nSliceHeight);
-            return OMX_ErrorBadParameter;
-        }
-
-        // set-up YUV format
-        image.mType = MediaImage::MEDIA_IMAGE_TYPE_YUV;
-        image.mNumPlanes = 3;
-        image.mBitDepth = 8;
-        image.mPlane[image.Y].mOffset = 0;
-        image.mPlane[image.Y].mColInc = 1;
-        image.mPlane[image.Y].mRowInc = pDescribeColorFormat->nStride;
-        image.mPlane[image.Y].mHorizSubsampling = 1;
-        image.mPlane[image.Y].mVertSubsampling = 1;
-
-        switch (fmt) {
-            case OMX_SPRD_COLOR_FormatYVU420SemiPlanar:
-            // NV21
-            image.mPlane[image.V].mOffset = pDescribeColorFormat->nStride*pDescribeColorFormat->nSliceHeight;
-            image.mPlane[image.V].mColInc = 2;
-            image.mPlane[image.V].mRowInc = pDescribeColorFormat->nStride;
-            image.mPlane[image.V].mHorizSubsampling = 2;
-            image.mPlane[image.V].mVertSubsampling = 2;
-
-            image.mPlane[image.U].mOffset = image.mPlane[image.V].mOffset + 1;
-            image.mPlane[image.U].mColInc = 2;
-            image.mPlane[image.U].mRowInc = pDescribeColorFormat->nStride;
-            image.mPlane[image.U].mHorizSubsampling = 2;
-            image.mPlane[image.U].mVertSubsampling = 2;
-            break;
-
-            case OMX_COLOR_FormatYUV420SemiPlanar:
-                // FIXME: NV21 for sw-encoder, NV12 for decoder and hw-encoder
-                // NV12
-                image.mPlane[image.U].mOffset = pDescribeColorFormat->nStride*pDescribeColorFormat->nSliceHeight;
-                image.mPlane[image.U].mColInc = 2;
-                image.mPlane[image.U].mRowInc = pDescribeColorFormat->nStride;
-                image.mPlane[image.U].mHorizSubsampling = 2;
-                image.mPlane[image.U].mVertSubsampling = 2;
-
-                image.mPlane[image.V].mOffset = image.mPlane[image.U].mOffset + 1;
-                image.mPlane[image.V].mColInc = 2;
-                image.mPlane[image.V].mRowInc = pDescribeColorFormat->nStride;
-                image.mPlane[image.V].mHorizSubsampling = 2;
-                image.mPlane[image.V].mVertSubsampling = 2;
-                break;
-
-            case OMX_COLOR_FormatYUV420Planar: // used for YV12
-                image.mPlane[image.U].mOffset = pDescribeColorFormat->nStride*pDescribeColorFormat->nSliceHeight;
-                image.mPlane[image.U].mColInc = 1;
-                image.mPlane[image.U].mRowInc = pDescribeColorFormat->nStride / 2;
-                image.mPlane[image.U].mHorizSubsampling = 2;
-                image.mPlane[image.U].mVertSubsampling = 2;
-
-                image.mPlane[image.V].mOffset = image.mPlane[image.U].mOffset
-                        + (pDescribeColorFormat->nStride * pDescribeColorFormat->nSliceHeight / 4);
-                image.mPlane[image.V].mColInc = 1;
-                image.mPlane[image.V].mRowInc = pDescribeColorFormat->nStride / 2;
-                image.mPlane[image.V].mHorizSubsampling = 2;
-                image.mPlane[image.V].mVertSubsampling = 2;
-                break;
-
-            default:
-                TRESPASS();
-        }
-
-        return OMX_ErrorNone;
-    }
-
     default:
         return SprdSimpleOMXComponent::internalGetParameter(index, params);
     }
@@ -1287,13 +1117,6 @@ OMX_ERRORTYPE SPRDAVCEncoder::internalSetParameter(
         }
 
         mVideoBitRate = bitRate->nTargetBitrate;
-        if(bitRate->eControlRate == OMX_Video_ControlRateConstant) {
-            //for samsung, samsung set cbr instead of mEncSceneMode.
-            //for sprd, volte set mEncSceneMode, wfd set mEncSceneMode and cbr.
-            if (!mSetEncMode)
-                mEncSceneMode = 1; //encode in volte mode.
-        }
-
         return OMX_ErrorNone;
     }
 
@@ -1307,10 +1130,8 @@ OMX_ERRORTYPE SPRDAVCEncoder::internalSetParameter(
 
         if (def->nPortIndex == 0) {
             if (def->format.video.eCompressionFormat != OMX_VIDEO_CodingUnused ||
-                    (def->format.video.eColorFormat != OMX_COLOR_FormatYUV420Flexible &&
-                     def->format.video.eColorFormat != OMX_SPRD_COLOR_FormatYVU420SemiPlanar &&
+                    (def->format.video.eColorFormat != OMX_COLOR_FormatYUV420Planar &&
                      def->format.video.eColorFormat != OMX_COLOR_FormatYUV420SemiPlanar &&
-                     def->format.video.eColorFormat != OMX_COLOR_FormatYUV420Planar &&
                      def->format.video.eColorFormat != OMX_COLOR_FormatAndroidOpaque)) {
                 return OMX_ErrorUndefined;
             }
@@ -1329,11 +1150,6 @@ OMX_ERRORTYPE SPRDAVCEncoder::internalSetParameter(
                 def->nBufferSize = bufferSize;
             }
         }
-        //translate Flexible 8-bit YUV format to our default YUV format
-        if (def->format.video.eColorFormat == OMX_COLOR_FormatYUV420Flexible) {
-            ALOGI("internalSetParameter, translate Flexible 8-bit YUV format to SPRD YVU420SemiPlanar");
-            def->format.video.eColorFormat = OMX_SPRD_COLOR_FormatYVU420SemiPlanar;
-        }
 
         OMX_ERRORTYPE err = SprdSimpleOMXComponent::internalSetParameter(index, params);
         if (OMX_ErrorNone != err) {
@@ -1375,19 +1191,17 @@ OMX_ERRORTYPE SPRDAVCEncoder::internalSetParameter(
             return OMX_ErrorUndefined;
         }
 
-        if (formatParams->nIndex > 3) {
+        if (formatParams->nIndex > 2) {
             return OMX_ErrorNoMore;
         }
 
         if (formatParams->nPortIndex == 0) {
             if (formatParams->eCompressionFormat != OMX_VIDEO_CodingUnused ||
                     ((formatParams->nIndex == 0 &&
-                      formatParams->eColorFormat != OMX_SPRD_COLOR_FormatYVU420SemiPlanar) ||
+                      formatParams->eColorFormat != OMX_COLOR_FormatYUV420Planar) ||
                      (formatParams->nIndex == 1 &&
                       formatParams->eColorFormat != OMX_COLOR_FormatYUV420SemiPlanar) ||
                      (formatParams->nIndex == 2 &&
-                      formatParams->eColorFormat != OMX_COLOR_FormatYUV420Planar) ||
-                     (formatParams->nIndex == 3 &&
                       formatParams->eColorFormat != OMX_COLOR_FormatAndroidOpaque) )) {
                 return OMX_ErrorUndefined;
             }
@@ -1441,18 +1255,18 @@ OMX_ERRORTYPE SPRDAVCEncoder::internalSetParameter(
     case OMX_IndexParamStoreMetaDataBuffer:
     {
         StoreMetaDataInBuffersParams *pStoreMetaData = (StoreMetaDataInBuffersParams *)params;
-        if (pStoreMetaData->nPortIndex != 0) {
-            ALOGE("%s: StoreMetadataInBuffersParams.nPortIndex not zero!",
-                    __FUNCTION__);
-            return OMX_ErrorUndefined;
+        if(0 == pStoreMetaData->nPortIndex)   /// input buffer
+        {
+           mStoreMetaData = pStoreMetaData->bStoreMetaData;
+           return OMX_ErrorNone;
+        }
+        else
+        {
+           //modified by mjx.due to I donot want to ACodec set mUseMetadataOnEncoderOutput
+           //trigger ACodec using  ACodec::allocateBuffersOnPort-->mOMX->useBuffer
+           return OMX_ErrorUndefined; ////currently not support output meta data buffer
         }
-
-        mStoreMetaData = pStoreMetaData->bStoreMetaData;
-        ALOGV("StoreMetaDataInBuffers set to: %s",
-                mStoreMetaData ? " true" : "false");
-        return OMX_ErrorNone;
     }
-
     case OMX_IndexParamPrependSPSPPSToIDR:
     {
         PrependSPSPPSToIDRFramesParams *pPrependSPSPPS = (PrependSPSPPSToIDRFramesParams *)params;
@@ -1460,12 +1274,10 @@ OMX_ERRORTYPE SPRDAVCEncoder::internalSetParameter(
         ALOGI("OMX_IndexParamPrependSPSPPSToIDR return ok");
         return OMX_ErrorNone;
     }
-
     case OMX_IndexParamVideoIntraRefresh:
     {
         return OMX_ErrorNone;   ///hw encoder may not support this mode
     }
-
     default:
         return SprdSimpleOMXComponent::internalSetParameter(index, params);
     }
@@ -1486,24 +1298,7 @@ OMX_ERRORTYPE SPRDAVCEncoder::setConfig(
             mKeyFrameRequested = pConfigIntraRefreshVOP->IntraRefreshVOP;
             return OMX_ErrorNone;
         }
-        case OMX_IndexConfigVideoBitrate:
-        {
-            OMX_VIDEO_CONFIG_BITRATETYPE *pConfigParams=
-             (OMX_VIDEO_CONFIG_BITRATETYPE *)params;
-            if (pConfigParams->nPortIndex != kOutputPortIndex) {
-                return OMX_ErrorBadPortIndex;
-            }
-            mBitrate = pConfigParams->nEncodeBitrate;
-            mIschangebitrate=1;
-            return OMX_ErrorNone;
-        }
-        case OMX_IndexConfigEncSceneMode:
-        {
-            int *pEncSceneMode = (int *)params;
-            mEncSceneMode = *pEncSceneMode;
-            mSetEncMode = true;
-            return OMX_ErrorNone;
-        }
+
         default:
             return SprdSimpleOMXComponent::setConfig(index, params);
     }
@@ -1515,20 +1310,200 @@ OMX_ERRORTYPE SPRDAVCEncoder::getExtensionIndex(
     if(strcmp(name, "OMX.google.android.index.storeMetaDataInBuffers") == 0) {
         *index = (OMX_INDEXTYPE) OMX_IndexParamStoreMetaDataBuffer;
         return OMX_ErrorNone;
-    } else if (strcmp(name, "OMX.google.android.index.describeColorFormat") == 0) {
-        *index = (OMX_INDEXTYPE) OMX_IndexParamDescribeColorFormat;
-        return OMX_ErrorNone;
-    } else if(strcmp(name, "OMX.google.android.index.prependSPSPPSToIDRFrames") == 0) {
+    }
+    if(strcmp(name, "OMX.google.android.index.prependSPSPPSToIDRFrames") == 0) {
         *index = (OMX_INDEXTYPE) OMX_IndexParamPrependSPSPPSToIDR;
         return OMX_ErrorNone;
-    }else if (strcmp(name, "OMX.sprd.index.EncSceneMode") == 0) {
-        *index = (OMX_INDEXTYPE) OMX_IndexConfigEncSceneMode;
-        return OMX_ErrorNone;
     }
-
     return SprdSimpleOMXComponent::getExtensionIndex(name, index);
 }
 
+
+
+#ifdef CONVERT_THREAD
+
+SPRDAVCEncoder::MyRGB2YUVThreadHandle::MyRGB2YUVThreadHandle(SPRDAVCEncoder *poutEnc,char relatedthreadNum)
+{
+    mPoutEnc = poutEnc;
+    mRelatedthreadNum = relatedthreadNum;
+}
+void SPRDAVCEncoder::MyRGB2YUVThreadHandle::onMessageReceived(const sp<AMessage> &msg)
+{
+    switch (msg->what()) {
+
+    case kWhatRgb2Yuv:
+    {
+
+        int64_t mBufNum = 0;
+        sp<RefBase> obj;
+        CHECK(msg->findObject("addr_object", &obj));
+        sp<msg_addr_for_convert>addr_object = static_cast<msg_addr_for_convert *>(obj.get());
+        //ALOGE("wfd:thread%d get msg.py:%p.puv:%p,vaddr:%p",mRelatedthreadNum,addr_object->py,addr_object->puv,addr_object->vaddr);
+        ConvertARGB888ToYUV420SemiPlanar_neon((uint8_t*)addr_object->vaddr, addr_object->py, addr_object->puv,mPoutEnc->mVideoWidth, mPoutEnc->mVideoHeight/CONVERT_MAX_THREAD_NUM, (mPoutEnc->mVideoWidth+15)&(~15), (mPoutEnc->mVideoHeight/CONVERT_MAX_THREAD_NUM+15)&(~15));
+        //ConvertARGB888ToYUV420SemiPlanar((uint8_t*)addr_object->vaddr, addr_object->py, addr_object->puv,mPoutEnc->mVideoWidth, mPoutEnc->mVideoHeight/CONVERT_MAX_THREAD_NUM, (mPoutEnc->mVideoWidth+15)&(~15), (mPoutEnc->mVideoHeight/CONVERT_MAX_THREAD_NUM+15)&(~15));
+        mPoutEnc->rgb2yuv_thread_status[mRelatedthreadNum] = RGB2YUR_THREAD_READY;
+        mPoutEnc->mConvertedBufAvailableCondition.signal();
+        break;
+    }
+
+    default:
+
+        TRESPASS();
+        break;
+    }
+}
+
+void SPRDAVCEncoder::sendConvertMessage(OMX_BUFFERHEADERTYPE *buffer)
+
+{
+    sp<AMessage> msg = new AMessage(kWhatConvert, mHandler_enc->id());
+    msg->setPointer("header", buffer);
+    msg->post();
+}
+
+
+
+void SPRDAVCEncoder::onMessageReceived(const sp<AMessage> &msg) {
+    switch (msg->what()) {
+    case kWhatConvert:
+    {
+        OMX_BUFFERHEADERTYPE *header;
+        CHECK(msg->findPointer("header", (void **)&header));
+
+        PortInfo *port = editPortInfo(OMX_DirInput);
+
+        if (mPbuf_yuv_v == NULL) {
+           int32 yuv_size = ((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15)) *3*CONVERT_MAX_ION_NUM/2;
+           if (mIOMMUEnabled) {
+               mYUVInPmemHeap = new MemoryHeapIon("/dev/ion", yuv_size, MemoryHeapBase::NO_CACHING, ION_HEAP_ID_MASK_SYSTEM);
+           } else {
+               mYUVInPmemHeap = new MemoryHeapIon("/dev/ion", yuv_size, MemoryHeapBase::NO_CACHING, ION_HEAP_ID_MASK_MM);
+           }
+           if (mYUVInPmemHeap->getHeapID() < 0) {
+               ALOGE("Failed to alloc yuv buffer");
+               return;
+           }
+           int ret,phy_addr, buffer_size;
+           if(mIOMMUEnabled) {
+               ret = mYUVInPmemHeap->get_mm_iova(&phy_addr, &buffer_size);
+           } else {
+               ret = mYUVInPmemHeap->get_phy_addr_from_ion(&phy_addr, &buffer_size);
+           }
+           if(ret) {
+               ALOGE("Failed to get_phy_addr_from_ion %d", ret);
+               return;
+           }
+           mPbuf_yuv_v =(uint8_t *) mYUVInPmemHeap->base();
+           mPbuf_yuv_p = (int32)phy_addr;
+           //mPbuf_yuv_size = (int32)buffer_size; //mjx note:buffer_size not equal the yuv_size.if used buffersize would make memory crash
+           mPbuf_yuv_size = (int32)yuv_size;
+           //ALOGI("wfd: yuv_size is %d, buffer_size is %d",yuv_size,buffer_size);
+        }
+        for (size_t j = 0; j < port->mBuffers.size(); ++j) {
+            BufferInfo *buffer = &port->mBuffers.editItemAt(j);
+
+            if (buffer->mHeader == header) {
+                OMX_BUFFERHEADERTYPE *inHeader = buffer->mHeader;
+                const void *inData = inHeader->pBuffer + inHeader->nOffset;
+                uint8_t *inputData = (uint8_t *) inData;
+                CHECK(inputData != NULL);
+                unsigned int type = *(unsigned int *) inputData;
+
+                if(mStoreMetaData &&(type == kMetadataBufferTypeGrallocSource))
+                {
+                    Mutex::Autolock autoLock(mLock_receive);
+                    //ALOGE("wfd: kWhatConvertThisBuffer,incoming buffer number:%llu",mIncomingBufNum);
+                    uint8_t* py;
+                    uint8_t* py_phy;
+                    const void *inData = inHeader->pBuffer + inHeader->nOffset;
+                    uint8_t *inputData = (uint8_t *) inData;
+                    CHECK(inputData != NULL);
+                    py = mPbuf_yuv_v+mPbuf_yuv_size*mBufIndex/CONVERT_MAX_ION_NUM;
+                    py_phy = (uint8_t*)(mPbuf_yuv_p+mPbuf_yuv_size*mBufIndex/CONVERT_MAX_ION_NUM);
+                    //ALOGE("wfd: mBufIndex:%d,mPbuf_yuv_size:%d.base_py:%p",mBufIndex,mPbuf_yuv_size,py);
+                    void* vaddr = NULL;
+                    GraphicBufferMapper &mapper = GraphicBufferMapper::get();
+                    buffer_handle_t buf = *((buffer_handle_t *)(inputData + 4));
+                    Rect bounds((mVideoWidth+15)&(~15), (mVideoHeight+15)&(~15));
+                    if (mapper.lock(buf, GRALLOC_USAGE_SW_READ_OFTEN|GRALLOC_USAGE_SW_WRITE_NEVER, bounds, &vaddr)) {
+                        return;
+                    }
+                    //send to multi threads
+                    int32 single_rgb_size = mVideoWidth * mVideoHeight*4;
+                    int32 single_yuv_size = ((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15)) *3/2;
+                    int64_t start_encode = systemTime();
+                    for(int j=0;j<CONVERT_MAX_THREAD_NUM;j++)
+                    {
+                        //ALOGI("wfd: send msg to:Thread%d.",j);
+                        rgb2yuv_thread_status[j] = RGB2YUR_THREAD_BUSY;
+                        sp<AMessage> msg = new AMessage(kWhatRgb2Yuv, mHandler_rgb2yuv[j]->id());
+                        sp<msg_addr_for_convert> addr_object = new msg_addr_for_convert;
+                        addr_object->buf_number = mIncomingBufNum;
+                        addr_object->internal_index = j;
+                        addr_object->py = py+((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15))*j/CONVERT_MAX_THREAD_NUM;
+                        addr_object->puv = py+((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15))+((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15))*j/(CONVERT_MAX_THREAD_NUM*2);
+                        addr_object->vaddr = (uint8_t*)vaddr+(single_rgb_size*j)/CONVERT_MAX_THREAD_NUM;
+                        msg->setObject("addr_object",addr_object);
+                        msg->post();
+                    }
+                    // check threads status.
+                    int ready_thread_num = 0;
+                    int64_t end_encode = systemTime();
+                    //ALOGI("wfd: total rgb-yuv send msg cost time: %d",(unsigned int)((end_encode-start_encode) / 1000000L));
+                    while(ready_thread_num<CONVERT_MAX_THREAD_NUM)
+                    {
+                        //mConvertedBufAvailableCondition.wait(mLock_con);
+                        mConvertedBufAvailableCondition.waitRelative(mLock_con, 5*1000*1000); //5ms
+                        for(int j=0;j<CONVERT_MAX_THREAD_NUM;j++)
+                        {
+                            if(rgb2yuv_thread_status[j] == RGB2YUR_THREAD_READY)
+                            ready_thread_num++;
+                        }
+                        //ALOGI("wfd: ready thread num:%d",ready_thread_num);
+                        if(ready_thread_num == CONVERT_MAX_THREAD_NUM)
+                        {
+                            break;
+                        }else
+                        {
+                            ready_thread_num=0;
+                        }
+                    }
+                    if (mapper.unlock(buf)) {
+                        return;
+                    }
+                    end_encode = systemTime();
+                    ALOGI("wfd: total rgb-yuv cost time: %d",(unsigned int)((end_encode-start_encode) / 1000000L));
+                    ConvertOutBufferInfo* info = new ConvertOutBufferInfo;
+                    if(info == NULL)
+                    {
+                        ALOGE("wfd:can not new ConvertOutBufferInfo buffer");
+                        return;
+                    }
+                    info->buf_number = mIncomingBufNum;
+                    info->py = py;
+                    info->py_phy = py_phy;
+                    mConvertOutBufQueue.push_back(info);
+                    mIncomingBufNum++;
+                    mBufIndex =(mBufIndex+1)%CONVERT_MAX_ION_NUM;
+                    mOutBufAvailableCondition.signal();
+                }
+                break;
+            }
+        }
+
+        break;
+    }
+
+    default:
+        TRESPASS();
+        break;
+    }
+}
+
+#endif
+
+
+
 void SPRDAVCEncoder::onQueueFilled(OMX_U32 portIndex) {
     if (mSignalledError || mSawInputEOS) {
         return;
@@ -1569,16 +1544,12 @@ void SPRDAVCEncoder::onQueueFilled(OMX_U32 portIndex) {
             memset(&pps_header, 0, sizeof(MMEncOut));
 
             ++mNumInputFrames;
-            if((ret = (*mH264EncGenHeader)(mHandle, &sps_header, 1)) < 0){
-                ALOGE("%s, line:%d, mH264EncGenHeader failed, ret: %d\n", __FUNCTION__, __LINE__, ret);
-                return;
-            }
-
+            ret = (*mH264EncGenHeader)(mHandle, &sps_header, 1);
             outHeader->nFilledLen = sps_header.strmSize;
             ALOGI("%s, %d, sps_header.strmSize: %d", __FUNCTION__, __LINE__, sps_header.strmSize);
 
             {   //added by xiaowei, 2013.10.08, for bug 220340.
-                uint8_t *p = (uint8_t *)(sps_header.pOutBuf);
+                uint8 *p = (uint8 *)(sps_header.pOutBuf);
                 ALOGI("sps: %0x, %0x, %0x, %0x, %0x, %0x, %0x, %0x, %0x, %0x, %0x,%0x, %0x, %0x, %0x, %0x",
                       p[0], p[1], p[2], p[3], p[4], p[5], p[6], p[7], p[8], p[9],p[10], p[11], p[12], p[13], p[14], p[15]);
 
@@ -1594,17 +1565,12 @@ void SPRDAVCEncoder::onQueueFilled(OMX_U32 portIndex) {
 
             memcpy(outPtr, sps_header.pOutBuf, sps_header.strmSize);
             outPtr+= sps_header.strmSize;
-
             ++mNumInputFrames;
-            if((ret = (*mH264EncGenHeader)(mHandle, &pps_header, 0)) < 0){
-                ALOGE("%s, line:%d, mH264EncGenHeader failed, ret: %d\n", __FUNCTION__, __LINE__, ret);
-                return;
-            }
-
+            ret = (*mH264EncGenHeader)(mHandle, &pps_header, 0);
             ALOGI("%s, %d, pps_header.strmSize: %d", __FUNCTION__, __LINE__, pps_header.strmSize);
 
             {   //added by xiaowei, 2013.10.08, for bug 220340.
-                uint8_t *p = (uint8_t *)(pps_header.pOutBuf);
+                uint8 *p = (uint8 *)(pps_header.pOutBuf);
                 ALOGI("pps: %0x, %0x, %0x, %0x, %0x, %0x, %0x, %0x,",
                       p[0], p[1], p[2], p[3], p[4], p[5], p[6], p[7]);
 
@@ -1620,7 +1586,6 @@ void SPRDAVCEncoder::onQueueFilled(OMX_U32 portIndex) {
 
             outHeader->nFilledLen += pps_header.strmSize;
             memcpy(outPtr, pps_header.pOutBuf, pps_header.strmSize);
-
             mSpsPpsHeaderReceived = true;
             CHECK_EQ(0, mNumInputFrames);  // 1st video frame is 0
             outHeader->nFlags = OMX_BUFFERFLAG_CODECCONFIG;
@@ -1630,7 +1595,7 @@ void SPRDAVCEncoder::onQueueFilled(OMX_U32 portIndex) {
             return;
         }
 
-        ALOGV("%s, line:%d, inHeader->nFilledLen: %d, mStoreMetaData: %d, mVideoColorFormat: 0x%x",
+        ALOGV("%s, %d, inHeader->nFilledLen: %d, mStoreMetaData: %d, mVideoColorFormat: 0x%x",
               __FUNCTION__, __LINE__, inHeader->nFilledLen, mStoreMetaData, mVideoColorFormat);
 
         // Save the input buffer info so that it can be
@@ -1659,149 +1624,103 @@ void SPRDAVCEncoder::onQueueFilled(OMX_U32 portIndex) {
             uint32_t height = 0;
             uint32_t x = 0;
             uint32_t y = 0;
-            bool needUnmap = false;
-            int bufFd = -1;
-            unsigned long iova = 0;
-            size_t iovaLen = 0;
 
             if (mStoreMetaData) {
-                unsigned int *mataData = (unsigned int *)inputData;
-                unsigned int type = *mataData++;
-
+                unsigned int type = *(unsigned int *) inputData;
                 if (type == kMetadataBufferTypeCameraSource) {
-                    py_phy = (uint8_t*)(*(unsigned long *)mataData);
-                    mataData += sizeof(unsigned long)/sizeof(unsigned int);
-                    py = (uint8_t*)(*(unsigned long *)mataData);
-                    mataData += sizeof(unsigned long)/sizeof(unsigned int);
-                    width = (uint32_t)(*((uint32_t *) mataData++));
-                    height = (uint32_t)(*((uint32_t *) mataData++));
-                    x = (uint32_t)(*((uint32_t *) mataData++));
-                    y = (uint32_t)(*((uint32_t *) mataData));
+                    py = (uint8_t*)(*((int *) inputData + 2));
+                    py_phy = (uint8_t*)(*((int *) inputData + 1));
+                    width = (uint32_t)(*((int *) inputData + 3));
+                    height = (uint32_t)(*((int *) inputData + 4));
+                    x = (uint32_t)(*((int *) inputData + 5));
+                    y = (uint32_t)(*((int *) inputData + 6));
                 } else if (type == kMetadataBufferTypeGrallocSource) {
-                    buffer_handle_t buf = *((buffer_handle_t *)(inputData + 4));
-                    struct private_handle_t *private_h = (struct private_handle_t*)buf;
-
-                    ALOGI("format:0x%x, usage:0x%x", private_h->format, private_h->usage);
-
-                    if ((mPbuf_yuv_v == NULL) &&
-                        !((mVideoColorFormat == OMX_SPRD_COLOR_FormatYVU420SemiPlanar ||
-                            mVideoColorFormat == OMX_COLOR_FormatYUV420SemiPlanar) &&
-                           (private_h->usage == GRALLOC_USAGE_HW_VIDEO_ENCODER))) {
-                        size_t yuv_size = ((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15)) *3/2;
-
+#ifdef CONVERT_THREAD
+                while(mConvertOutBufQueue.empty())
+                {
+                    mOutBufAvailableCondition.wait(mLock_convert);
+                }
+                ConvertOutBufferInfo *BufInfo = *mConvertOutBufQueue.begin();
+                py = BufInfo->py;
+                py_phy = BufInfo->py_phy;
+                mConvertOutBufQueue.erase(mConvertOutBufQueue.begin());
+                delete BufInfo;
+                mCurrentNeedBufNum++;
+#else
+                    if (mPbuf_yuv_v == NULL) {
+                        int32 yuv_size = ((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15)) *3/2;
                         if (mIOMMUEnabled) {
-                            mYUVInPmemHeap = new MemoryHeapIon("/dev/ion", yuv_size, MemoryHeapIon::NO_CACHING, ION_HEAP_ID_MASK_SYSTEM);
+                            mYUVInPmemHeap = new MemoryHeapIon("/dev/ion", yuv_size, MemoryHeapBase::NO_CACHING, ION_HEAP_ID_MASK_SYSTEM);
                         } else {
-                            mYUVInPmemHeap = new MemoryHeapIon("/dev/ion", yuv_size, MemoryHeapIon::NO_CACHING, ION_HEAP_ID_MASK_MM);
+                            mYUVInPmemHeap = new MemoryHeapIon("/dev/ion", yuv_size, MemoryHeapBase::NO_CACHING, ION_HEAP_ID_MASK_MM);
                         }
                         if (mYUVInPmemHeap->getHeapID() < 0) {
                             ALOGE("Failed to alloc yuv buffer");
                             return;
                         }
-
-                        int ret;
-                        unsigned long phy_addr;
-                        size_t buffer_size;
+                        int ret,phy_addr, buffer_size;
                         if(mIOMMUEnabled) {
-                            ret = mYUVInPmemHeap->get_iova(mIOMMUID, &phy_addr, &buffer_size);
+                            ret = mYUVInPmemHeap->get_mm_iova(&phy_addr, &buffer_size);
                         } else {
                             ret = mYUVInPmemHeap->get_phy_addr_from_ion(&phy_addr, &buffer_size);
                         }
                         if(ret) {
-                            ALOGE("Failed to get_iova or get_phy_addr_from_ion %d", ret);
+                            ALOGE("Failed to get_phy_addr_from_ion %d", ret);
                             return;
                         }
-
-                        mPbuf_yuv_v =(uint8_t *) mYUVInPmemHeap->getBase();
-                        mPbuf_yuv_p = phy_addr;
-                        mPbuf_yuv_size = buffer_size;
+                        mPbuf_yuv_v =(uint8_t *) mYUVInPmemHeap->base();
+                        mPbuf_yuv_p = (int32)phy_addr;
+                        mPbuf_yuv_size = (int32)buffer_size;
                     }
 
                     py = mPbuf_yuv_v;
                     py_phy = (uint8_t*)mPbuf_yuv_p;
 
                     GraphicBufferMapper &mapper = GraphicBufferMapper::get();
+                    buffer_handle_t buf = *((buffer_handle_t *)(inputData + 4));
                     Rect bounds((mVideoWidth+15)&(~15), (mVideoHeight+15)&(~15));
 
                     void* vaddr;
                     if (mapper.lock(buf, GRALLOC_USAGE_SW_READ_OFTEN|GRALLOC_USAGE_SW_WRITE_NEVER, bounds, &vaddr)) {
-                        ALOGE("%s, line:%d, mapper.lock failed", __FUNCTION__, __LINE__);
                         return;
                     }
 
                     if (mVideoColorFormat == OMX_COLOR_FormatYUV420Planar) {
-                        ConvertYUV420PlanarToYVU420SemiPlanar((uint8_t*)vaddr, py, mVideoWidth, mVideoHeight,
+                        ConvertYUV420PlanarToYUV420SemiPlanar((uint8_t*)vaddr, py, mVideoWidth, mVideoHeight,
                                                               (mVideoWidth + 15) & (~15), (mVideoHeight + 15) & (~15));
                     } else if(mVideoColorFormat == OMX_COLOR_FormatAndroidOpaque) {
-                        if(private_h->format == HAL_PIXEL_FORMAT_YCrCb_420_SP) {
-                            if (private_h->usage == GRALLOC_USAGE_HW_VIDEO_ENCODER) {
-                                unsigned long py_addr=0;
-                                size_t buf_size=0;
-                                int fd = private_h->share_fd;
-                                int ret = 0;
-
-                                if (mIOMMUEnabled) {
-                                    ret = MemoryHeapIon::Get_iova(ION_MM, fd,&py_addr,&buf_size);
-                                } else {
-                                    ret = MemoryHeapIon::Get_phy_addr_from_ion(fd,&py_addr,&buf_size);
-                                }
-                                if(ret) {
-                                    ALOGE("Failed to Get_iova or Get_phy_addr_from_ion %d", ret);
-                                    return;
-                                }
-                                if (mIOMMUEnabled) {
-                                    needUnmap = true;
-                                    bufFd = fd;
-                                    iova = py_addr;
-                                    iovaLen = buf_size;
-                                }
-
-                                py = (uint8_t*)vaddr;
-                                py_phy = (uint8_t*)py_addr;
-                            } else {
-                                memcpy(py, vaddr, ((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15)) * 3/2);
+                        struct private_handle_t *pH = (struct private_handle_t *)buf;
+                        private_handle_t* pBuf = (private_handle_t* )buf;
+                        ALOGI("OMX_COLOR_FormatAndroidOpaque.pBuf->format:%d",pBuf->format);
+                        ConvertARGB888ToYUV420SemiPlanar_neon((uint8_t*)vaddr, py, py+(((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15))),mVideoWidth, mVideoHeight, (mVideoWidth+15)&(~15), (mVideoHeight+15)&(~15));
+                    } else if(mVideoColorFormat == OMX_COLOR_FormatYUV420SemiPlanar) {
+                        struct private_handle_t *pH = (struct private_handle_t *)buf;
+                        int64_t start_queue = systemTime();
+                        int size = 0;
+                        private_handle_t* pBuf = (private_handle_t* )buf;
+                        //ALOGI("meijiaxi:pBuf->format:%d",pBuf->format);
+                        if(HAL_PIXEL_FORMAT_YCbCr_420_SP == pBuf->format){
+                            if (mIOMMUEnabled) {
+                                MemoryHeapIon::Get_mm_iova(pBuf->share_fd, &(pBuf->phyaddr), &size);
+                            }else{
+                                MemoryHeapIon::Get_phy_addr_from_ion(pBuf->share_fd, &(pBuf->phyaddr), &size);
                             }
-                        } else {
-                            //ConvertARGB888ToYVU420SemiPlanar((uint8_t*)vaddr, py, py+(((mVideoWidth+15)&(~15)) * mVideoHeight), mVideoWidth, mVideoHeight, (mVideoWidth+15)&(~15), (mVideoHeight+15)&(~15));
-                            ConvertARGB888ToYVU420SemiPlanar_neon((uint8_t*)vaddr, py, py+(((mVideoWidth+15)&(~15)) * mVideoHeight), mVideoWidth, mVideoHeight, (mVideoWidth+15)&(~15), (mVideoHeight+15)&(~15));
-                        }
-                    } else if(private_h->usage == GRALLOC_USAGE_HW_VIDEO_ENCODER ||
-                                mVideoColorFormat == OMX_COLOR_FormatYUV420SemiPlanar ||
-                                mVideoColorFormat == OMX_SPRD_COLOR_FormatYVU420SemiPlanar) {
-                        unsigned long py_addr=0;
-                        size_t buf_size=0;
-                        int fd = private_h->share_fd;
-                        int ret = 0;
-                        //ALOGD("private_h->format:0x%x",private_h->format);
-
-                        if (mIOMMUEnabled) {
-                            ret = MemoryHeapIon::Get_iova(mIOMMUID, fd,&py_addr,&buf_size);
-                        } else {
-                            ret = MemoryHeapIon::Get_phy_addr_from_ion(fd,&py_addr,&buf_size);
-                        }
-                        if(ret) {
-                            ALOGE("Failed to Get_iova or Get_phy_addr_from_ion %d", ret);
-                            return;
-                        }
-                        if (mIOMMUEnabled) {
-                            needUnmap = true;
-                            bufFd = fd;
-                            iova = py_addr;
-                            iovaLen = buf_size;
+                            py_phy = (uint8_t*)(pBuf->phyaddr);
+                            py = (uint8_t*)vaddr;
+                            int64_t end_queue = systemTime();
+                            ALOGI("wfd: get yuv data directly. OMX_COLOR_FormatYUV420SemiPlanar.color format:%d,queue yuv buffer time: %d ms",pBuf->format,(unsigned int)((end_queue-start_queue) / 1000000L));
+                        }else{
+                            ALOGI("wfd:color not match.OMX_COLOR_FormatYUV420SemiPlanar,we need HAL_PIXEL_FORMAT_YCbCr_420_SP.but get color format:%d",pBuf->format);
                         }
-
-                        py = (uint8_t*)vaddr;
-                        py_phy = (uint8_t*)py_addr;
-                        //ALOGD("%s, mIOMMUEnabled = %d, fd = 0x%lx, py = 0x%lx, py_phy = 0x%lx",__FUNCTION__, mIOMMUEnabled, fd, py, py_phy);
-                    } else {
+                    }
+                    else {
                         memcpy(py, vaddr, ((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15)) * 3/2);
                     }
 
                     if (mapper.unlock(buf)) {
-                        ALOGE("%s, line:%d, mapper.unlock failed", __FUNCTION__, __LINE__);
                         return;
                     }
-
+#endif //end CONVERT_THREAD
                 } else {
                     ALOGE("Error MetadataBufferType %d", type);
                     return;
@@ -1810,60 +1729,46 @@ void SPRDAVCEncoder::onQueueFilled(OMX_U32 portIndex) {
                 if (mPbuf_yuv_v == NULL) {
                     int32 yuv_size = ((mVideoWidth+15)&(~15))*((mVideoHeight+15)&(~15))*3/2;
                     if(mIOMMUEnabled) {
-                        mYUVInPmemHeap = new MemoryHeapIon("/dev/ion", yuv_size, MemoryHeapIon::NO_CACHING, ION_HEAP_ID_MASK_SYSTEM);
+                        mYUVInPmemHeap = new MemoryHeapIon("/dev/ion", yuv_size, MemoryHeapBase::NO_CACHING, ION_HEAP_ID_MASK_SYSTEM);
                     } else {
-                        mYUVInPmemHeap = new MemoryHeapIon("/dev/ion", yuv_size, MemoryHeapIon::NO_CACHING, ION_HEAP_ID_MASK_MM);
+                        mYUVInPmemHeap = new MemoryHeapIon("/dev/ion", yuv_size, MemoryHeapBase::NO_CACHING, ION_HEAP_ID_MASK_MM);
                     }
                     if (mYUVInPmemHeap->getHeapID() < 0) {
                         ALOGE("Failed to alloc yuv buffer");
                         return;
                     }
-
-                    int ret;
-                    unsigned long phy_addr;
-                    size_t buffer_size;
+                    int ret,phy_addr, buffer_size;
                     if(mIOMMUEnabled) {
-                        ret = mYUVInPmemHeap->get_iova(mIOMMUID, &phy_addr, &buffer_size);
+                        ret = mYUVInPmemHeap->get_mm_iova(&phy_addr, &buffer_size);
                     } else {
                         ret = mYUVInPmemHeap->get_phy_addr_from_ion(&phy_addr, &buffer_size);
                     }
                     if(ret) {
-                        ALOGE("Failed to get_iova or get_phy_addr_from_ion %d", ret);
+                        ALOGE("Failed to get_phy_addr_from_ion %d", ret);
                         return;
                     }
-
-                    mPbuf_yuv_v =(uint8_t *) mYUVInPmemHeap->getBase();
-                    mPbuf_yuv_p = phy_addr;
-                    mPbuf_yuv_size = buffer_size;
+                    mPbuf_yuv_v =(uint8_t *) mYUVInPmemHeap->base();
+                    mPbuf_yuv_p = (int32)phy_addr;
+                    mPbuf_yuv_size = (int32)buffer_size;
                 }
 
                 py = mPbuf_yuv_v;
                 py_phy = (uint8_t*)mPbuf_yuv_p;
 
                 if (mVideoColorFormat == OMX_COLOR_FormatYUV420Planar) {
-                    ConvertYUV420PlanarToYVU420SemiPlanar(inputData, py, mVideoWidth, mVideoHeight,
+                    ConvertYUV420PlanarToYUV420SemiPlanar(inputData, py, mVideoWidth, mVideoHeight,
                                                           (mVideoWidth + 15) & (~15), (mVideoHeight + 15) & (~15));
                 } else if(mVideoColorFormat == OMX_COLOR_FormatAndroidOpaque) {
-                   // ConvertARGB888ToYVU420SemiPlanar(inputData, py, py+(((mVideoWidth+15)&(~15)) * mVideoHeight), mVideoWidth, mVideoHeight, (mVideoWidth+15)&(~15), (mVideoHeight+15)&(~15));
-                    ConvertARGB888ToYVU420SemiPlanar_neon(inputData, py, py+(((mVideoWidth+15)&(~15)) * mVideoHeight), mVideoWidth, mVideoHeight, (mVideoWidth+15)&(~15), (mVideoHeight+15)&(~15));
+                    //ConvertARGB888ToYUV420SemiPlanar(inputData, py, mVideoWidth, mVideoHeight, (mVideoWidth+15)&(~15), (mVideoHeight+15)&(~15));
+                    ConvertARGB888ToYUV420SemiPlanar_neon(inputData, py, py+(((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15))),mVideoWidth, mVideoHeight, (mVideoWidth+15)&(~15), (mVideoHeight+15)&(~15));
                 } else {
                     memcpy(py, inputData, ((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15)) * 3/2);
                 }
             }
 
-            // vid_in.time_stamp is not use for now.
             vid_in.time_stamp = (inHeader->nTimeStamp + 500) / 1000;  // in ms;
             vid_in.channel_quality = 1;
-            if (mIschangebitrate)
-            {
-                vid_in.bitrate=mBitrate;
-                vid_in.ischangebitrate = true;
-                mIschangebitrate =false;
-            }
-            else
-            {
-                vid_in.ischangebitrate = false;
-            }
+
             vid_in.needIVOP = false;    // default P frame
             if (mKeyFrameRequested || (mNumInputFrames == 0)) {
                 vid_in.needIVOP = true;    // I frame
@@ -1874,15 +1779,13 @@ void SPRDAVCEncoder::onQueueFilled(OMX_U32 portIndex) {
             vid_in.p_src_v = 0;
             vid_in.p_src_y_phy = py_phy;
             vid_in.p_src_v_phy = 0;
-
             if(width != 0 && height != 0) {
-                vid_in.p_src_u = py + width*height;
-                vid_in.p_src_u_phy = py_phy + width*height;
+                vid_in.p_src_u = py + ((width+15)&(~15)) * ((height+15)&(~15));
+                vid_in.p_src_u_phy = py_phy + ((width+15)&(~15)) * ((height+15)&(~15));
             } else {
-                vid_in.p_src_u = py + ((mVideoWidth + 0xf) & ~0xf) * mVideoHeight;
-                vid_in.p_src_u_phy = py_phy + ((mVideoWidth + 0xf) & ~0xf) * mVideoHeight;
+                vid_in.p_src_u = py + ((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15));
+                vid_in.p_src_u_phy = py_phy + ((mVideoWidth+15)&(~15)) * ((mVideoHeight+15)&(~15));
             }
-
             vid_in.org_img_width = (int32_t)width;
             vid_in.org_img_height = (int32_t)height;
             vid_in.crop_x = (int32_t)x;
@@ -1899,24 +1802,19 @@ void SPRDAVCEncoder::onQueueFilled(OMX_U32 portIndex) {
             int64_t end_encode = systemTime();
             ALOGI("H264EncStrmEncode[%lld] %dms, in {%p-%p, %dx%d}, out {%p-%d, %d}, wh{%d, %d}, xy{%d, %d}",
                   mNumInputFrames, (unsigned int)((end_encode-start_encode) / 1000000L), py, py_phy,
-                  mVideoWidth, mVideoHeight, vid_out.pOutBuf, vid_out.strmSize, vid_out.vopType, width, height, x, y);
-
-            if (needUnmap) {
-                ALOGV("Free_iova, fd: %d, iova: 0x%lx, size: %zd", bufFd, iova, iovaLen);
-                MemoryHeapIon::Free_iova(mIOMMUID, bufFd, iova, iovaLen);
-            }
-
+                  mVideoWidth, mVideoHeight, vid_out.pOutBuf, vid_out.strmSize,vid_out.vopType, width, height, x, y);
             if ((vid_out.strmSize < 0) || (ret != MMENC_OK)) {
                 ALOGE("Failed to encode frame %lld, ret=%d", mNumInputFrames, ret);
-#if 0  //removed by xiaowei, 20131017, for cr224544              
+#if 0  //removed by xiaowei, 20131017, for cr224544
                 mSignalledError = true;
                 notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 #endif
             } else {
+
                 ALOGI("%s, %d, out_stream_ptr: %p", __FUNCTION__, __LINE__, outPtr);
 
                 {   //added by xiaowei, 2013.10.08, for bug 220340.
-                    uint8_t *p = (uint8_t *)(vid_out.pOutBuf);
+                    uint8 *p = (uint8 *)(vid_out.pOutBuf);
                     ALOGI("frame: %0x, %0x, %0x, %0x, %0x, %0x, %0x, %0x,",
                           p[0], p[1], p[2], p[3], p[4], p[5], p[6], p[7]);
 
@@ -1987,6 +1885,14 @@ bool SPRDAVCEncoder::openEncoder(const char* libName)
         return false;
     }
 
+    mH264EncGetCodecCapability = (FT_H264EncGetCodecCapability)dlsym(mLibHandle, "H264EncGetCodecCapability");
+    if(mH264EncGetCodecCapability == NULL) {
+        ALOGE("Can't find H264EncGetCodecCapability in %s",libName);
+        dlclose(mLibHandle);
+        mLibHandle = NULL;
+        return false;
+    }
+
     mH264EncPreInit = (FT_H264EncPreInit)dlsym(mLibHandle, "H264EncPreInit");
     if(mH264EncPreInit == NULL) {
         ALOGE("Can't find mH264EncPreInit in %s",libName);
@@ -2040,15 +1946,6 @@ bool SPRDAVCEncoder::openEncoder(const char* libName)
         ALOGE("Can't find H264EncRelease in %s",libName);
         dlclose(mLibHandle);
         mLibHandle = NULL;
-        return false;
-    }
-
-    mH264EncGetCodecCapability = (FT_H264EncGetCodecCapability)dlsym(mLibHandle, "H264EncGetCodecCapability");
-    if(mH264EncGetCodecCapability == NULL) {
-        ALOGE("Can't find H264EncGetCodecCapability in %s",libName);
-        dlclose(mLibHandle);
-        mLibHandle = NULL;
-        return false;
     }
 
     return true;
diff --git a/omx-components/video/avc_sprd/sc8830/enc/SPRDAVCEncoder.h b/omx-components/video/avc_sprd/sc8830/enc/SPRDAVCEncoder.h
index 9805266..fd471ec 100644
--- a/omx-components/video/avc_sprd/sc8830/enc/SPRDAVCEncoder.h
+++ b/omx-components/video/avc_sprd/sc8830/enc/SPRDAVCEncoder.h
@@ -20,15 +20,24 @@
 #include "SprdSimpleOMXComponent.h"
 
 #include "avc_enc_api.h"
+#include <utils/threads.h>
 
 #define H264ENC_INTERNAL_BUFFER_SIZE  (0x200000)
-//#define ONEFRAME_BITSTREAM_BFR_SIZE	(1500*1024)  //for bitstream size of one encoded frame.
+#define ONEFRAME_BITSTREAM_BFR_SIZE	(1500*1024)  //for bitstream size of one encoded frame.
 
 namespace android {
 
 //#define SPRD_DUMP_YUV
 //#define SPRD_DUMP_BS
 
+#if 0
+//in wifidisplay case .get rgb data from surfaceflinger
+#define CONVERT_THREAD
+#endif
+
+#ifdef CONVERT_THREAD
+struct ALooper;
+#endif
 struct SPRDAVCEncoder :  public SprdSimpleOMXComponent {
     SPRDAVCEncoder(
         const char *name,
@@ -48,6 +57,12 @@ struct SPRDAVCEncoder :  public SprdSimpleOMXComponent {
 
     virtual void onQueueFilled(OMX_U32 portIndex);
 
+#ifdef	CONVERT_THREAD
+	void onQueueConverted(uint64_t incoming_buf_nu,uint8_t BufIndex);
+	virtual void sendConvertMessage(OMX_BUFFERHEADERTYPE *buffer);
+    void onMessageReceived(const sp<AMessage> &msg);
+
+#endif
     virtual OMX_ERRORTYPE getExtensionIndex(
         const char *name, OMX_INDEXTYPE *index);
 
@@ -56,67 +71,124 @@ protected:
 
 private:
     enum {
-        kNumBuffers = 4,
+        kNumBuffers = 2,
     };
 
+    // OMX port indexes that refer to input and
+    // output ports respectively
+    static const uint32_t kInputPortIndex = 0;
+    static const uint32_t kOutputPortIndex = 1;
+
     // OMX input buffer's timestamp and flags
     typedef struct {
         int64_t mTimeUs;
         int32_t mFlags;
     } InputBufferInfo;
 
-    tagAVCHandle          *mHandle;
-    tagAVCEncParam        *mEncParams;
-    MMEncConfig *mEncConfig;
-    uint32_t              *mSliceGroup;
-    Vector<InputBufferInfo> mInputBufferInfoVec;
+#ifdef CONVERT_THREAD
+    enum {
+    kWhatConvert,
+    };
 
-    int64_t  mNumInputFrames;
-    int64_t  mPrevTimestampUs;
-    int mSetFreqCount;
-    int mBitrate;
-    int mEncSceneMode;
-    bool mSetEncMode;
+    sp<ALooper> mLooper_enc;
+    sp<AHandlerReflector<SPRDAVCEncoder> > mHandler_enc;
+    typedef struct {
+        uint64_t buf_number;
+        uint8_t *py;   //virtual addr
+        uint8_t *py_phy;    //phy addr
+    } ConvertOutBufferInfo;
+    List<ConvertOutBufferInfo *> mConvertOutBufQueue;
+    struct msg_addr_for_convert : public RefBase {
+        uint64_t buf_number;
+        uint8_t internal_index;
+        uint8_t *py;
+        uint8_t *puv;
+        void *vaddr;
+    } ;
+    Condition mConvertedBufAvailableCondition;
+    Condition mOutBufAvailableCondition;
+    Mutex mLock_con;
+    Mutex mLock_receive;
+    Mutex mLock_convert;
+    Mutex mLock_map;
+    int64_t mIncomingBufNum;
+    int64_t mCurrentNeedBufNum;
+    #define CONVERT_MAX_THREAD_NUM 2
+    #define CONVERT_MAX_ION_NUM 4 //sync with nBufferCountMin
+    uint8_t         mBufIndex;
+    struct MyRGB2YUVThreadHandle :public AHandler
+    {
+        public:
+        MyRGB2YUVThreadHandle(SPRDAVCEncoder *poutEnc,char relatedthreadNum);
+        virtual void onMessageReceived(const sp<AMessage> &msg);
+        SPRDAVCEncoder * mPoutEnc;
+        char mRelatedthreadNum;
+        friend struct SPRDAVCEncoder;
+    };
+    enum {
+        RGB2YUR_THREAD_STOPED,
+        RGB2YUR_THREAD_READY,
+        RGB2YUR_THREAD_BUSY,
+    };
+    char rgb2yuv_thread_status[CONVERT_MAX_THREAD_NUM];
+    sp<ALooper> mLooper_rgb2yuv[CONVERT_MAX_THREAD_NUM];
+    sp<MyRGB2YUVThreadHandle> mHandler_rgb2yuv[CONVERT_MAX_THREAD_NUM];
+    enum {
+        kWhatRgb2Yuv,
+    };
+#endif
+
+    OMX_BOOL mStoreMetaData;
+    OMX_BOOL mPrependSPSPPS;
+    sp<MemoryHeapIon> mYUVInPmemHeap;
+    unsigned char* mPbuf_yuv_v;
+    int32 mPbuf_yuv_p;
+    int32 mPbuf_yuv_size;
+
+    bool mIOMMUEnabled;
+    uint8_t *mPbuf_inter;
+
+    sp<MemoryHeapIon> mPmem_stream;
+    unsigned char* mPbuf_stream_v;
+    int32 mPbuf_stream_p;
+    int32 mPbuf_stream_size;
+
+    sp<MemoryHeapIon> mPmem_extra;
+    unsigned char* mPbuf_extra_v;
+    int32  mPbuf_extra_p;
+    int32  mPbuf_extra_size;
+
+    MMEncVideoInfo mEncInfo;
+    MMEncCapability mCapability;
 
     int32_t  mVideoWidth;
     int32_t  mVideoHeight;
     int32_t  mVideoFrameRate;
     int32_t  mVideoBitRate;
     int32_t  mVideoColorFormat;
-
-    OMX_BOOL mStoreMetaData;
-    OMX_BOOL mPrependSPSPPS;
-    bool     mIOMMUEnabled;
-    int mIOMMUID;
+    AVCProfile mAVCEncProfile;
+    AVCLevel   mAVCEncLevel;
+    OMX_U32 mPFrames;
+    int64_t  mNumInputFrames;
+    int64_t  mPrevTimestampUs;
     bool     mStarted;
     bool     mSpsPpsHeaderReceived;
     bool     mReadyForNextFrame;
     bool     mSawInputEOS;
     bool     mSignalledError;
-    bool     mKeyFrameRequested;
-    bool     mIschangebitrate;
-    uint8_t *mPbuf_inter;
-
-    sp<MemoryHeapIon> mYUVInPmemHeap;
-    uint8_t *mPbuf_yuv_v;
-    unsigned long mPbuf_yuv_p;
-    size_t mPbuf_yuv_size;
+    //bool     mIsIDRFrame;
 
-    sp<MemoryHeapIon> mPmem_stream;
-    uint8_t *mPbuf_stream_v;
-    unsigned long mPbuf_stream_p;
-    size_t mPbuf_stream_size;
-
-    sp<MemoryHeapIon> mPmem_extra;
-    uint8_t *mPbuf_extra_v;
-    unsigned long  mPbuf_extra_p;
-    size_t  mPbuf_extra_size;
+    tagAVCHandle          *mHandle;
+    tagAVCEncParam        *mEncParams;
+    MMEncConfig *mEncConfig;
+    uint32_t              *mSliceGroup;
+//    Vector<MediaBuffer *> mOutputBuffers;
+    Vector<InputBufferInfo> mInputBufferInfoVec;
 
-    AVCProfile mAVCEncProfile;
-    AVCLevel   mAVCEncLevel;
-    OMX_U32 mPFrames;
+    int mSetFreqCount;
 
     void* mLibHandle;
+    FT_H264EncGetCodecCapability	mH264EncGetCodecCapability;
     FT_H264EncPreInit        mH264EncPreInit;
     FT_H264EncInit        mH264EncInit;
     FT_H264EncSetConf        mH264EncSetConf;
@@ -124,10 +196,6 @@ private:
     FT_H264EncStrmEncode        mH264EncStrmEncode;
     FT_H264EncGenHeader        mH264EncGenHeader;
     FT_H264EncRelease        mH264EncRelease;
-    FT_H264EncGetCodecCapability	mH264EncGetCodecCapability;
-
-    MMEncVideoInfo mEncInfo;
-    MMEncCapability mCapability;
 
 #ifdef SPRD_DUMP_YUV
     FILE* mFile_yuv;
@@ -137,14 +205,20 @@ private:
     FILE* mFile_bs;
 #endif
 
+    bool mKeyFrameRequested;
+
     void initPorts();
     OMX_ERRORTYPE initEncParams();
     OMX_ERRORTYPE initEncoder();
     OMX_ERRORTYPE releaseEncoder();
     OMX_ERRORTYPE releaseResource();
+//    void releaseOutputBuffers();
     bool openEncoder(const char* libName);
 
     DISALLOW_EVIL_CONSTRUCTORS(SPRDAVCEncoder);
+
+friend struct MyRGB2YUVThreadHandle;
+
 };
 
 }  // namespace android
diff --git a/omx-components/video/avc_sprd/sc8830/enc/avc_enc_api.h b/omx-components/video/avc_sprd/sc8830/enc/avc_enc_api.h
index 9acae94..c4e21bc 100644
--- a/omx-components/video/avc_sprd/sc8830/enc/avc_enc_api.h
+++ b/omx-components/video/avc_sprd/sc8830/enc/avc_enc_api.h
@@ -190,7 +190,7 @@ typedef enum
 typedef struct
 {
     uint8 *common_buffer_ptr;     // Pointer to buffer used when decoding
-    unsigned long common_buffer_ptr_phy;
+    void *common_buffer_ptr_phy;
     uint32	size;            		// Number of bytes decoding buffer
 
     int32 	frameBfr_num;			//YUV frame buffer number
@@ -219,7 +219,8 @@ typedef struct
 //    int32	uv_interleaved;				//tmp add
     int32    yuv_format;
     int32    b_anti_shake;
-    int32    cabac_en;
+
+    int32 cabac_en;
 } MMEncVideoInfo;
 
 // Encoder config structure
@@ -239,8 +240,7 @@ typedef struct
 
     uint32	profileAndLevel;
 
-    uint32  PrependSPSPPSEnalbe;        // 0: disable, 1: disable
-    uint32  EncSceneMode;
+    uint32 PrependSPSPPSEnalbe;	// 0: disable, 1: disable
 } MMEncConfig;
 
 // Encoder input structure
@@ -262,8 +262,6 @@ typedef struct
     int32    org_img_height;
     int32    crop_x;
     int32    crop_y;
-    int32    bitrate;
-    bool     ischangebitrate;
 } MMEncIn;
 
 // Encoder output structure
